{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c3b160",
   "metadata": {},
   "source": [
    "# **Orchestrating a Retriever Pipeline with Azure AI Search**\n",
    "\n",
    "Project Outline:\n",
    "1. Setting Up Azure AI Search, Azure Blob Storage and Azure Open AI\n",
    "2. Document Preprocessing \n",
    "3. Embedding & Uploading to Azure AI Search \n",
    "4. Retrieval Pipeline \n",
    "5. Orchestrate with LLM \n",
    "6. Evaluation (Relevancy Score)\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f04433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os \n",
    "## You need these to securely connect to Azure Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c29b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\") # URL of your Azure Search AI \n",
    "credential = AzureKeyCredential(os.getenv(\"AZURE_SEARCH_KEY\")) if os.getenv(\"AZURE_SEARCH_KEY\") else DefaultAzureCredential() # Either the Admin Key or DefaultAzureCredential for authentication\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\") # Name of your Azure Search Index\n",
    "blob_connection_string = os.getenv(\"AZURE_BLOB_CONN_STR\") # Connection string to your Azure Blob Storage\n",
    "blob_container_name = os.getenv(\"AZURE_BLOB_CONTAINER\") # Name of your Azure Blob Storage Container\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\") # URL of your Azure OpenAI Service\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\") # Key for your Azure OpenAI Service\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\") # Name of your Azure OpenAI Embedding Deployment\n",
    "azure_openai_model_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\") \n",
    "azure_openai_model_dimensions = int(os.getenv(\"AZURE_OPENAI_MODEL_DIMENSIONS\", 1024)) # Dimensions of your Azure OpenAI Embedding Model\n",
    "\n",
    "azure_ai_services_key = os.getenv(\"AZURE_AI_SERVICE\") # Key for your Azure AI Service (Document Intelligence)\n",
    "azure_ai_services_endpoint = os.getenv(\"AZURE_AI_SERVICE_ENDPOINT\") # Endpoint for your Azure AI Service (Document Intelligence)\n",
    "# Make sure you don't enable OCR or Markdown parsing at the same time, because Document Layout Skill is exclusive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed8e88",
   "metadata": {},
   "source": [
    "## Connect to Blob Storage and Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c13271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded Leave Policy_Onsite.pdf to Blob Storage\n",
      "Uploaded Maternity Leave and Paternity Leave policy-Offshore.pdf to Blob Storage\n",
      "Uploaded Leave Policy-Offshore.pdf to Blob Storage\n",
      "Uploaded Sabbatical_Long Leave Policy-Offshore.pdf to Blob Storage\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import glob\n",
    "\n",
    "def upload_sample_documents(blob_connection_string, blob_container_name, documents_directory, use_user_identity=False):\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(\n",
    "        logging_enable=True,\n",
    "        conn_str=blob_connection_string,\n",
    "        credential=DefaultAzureCredential() if use_user_identity else None\n",
    "    )\n",
    "    container_client = blob_service_client.get_container_client(blob_container_name)\n",
    "    if not container_client.exists():\n",
    "        container_client.create_container()\n",
    "    \n",
    "    files = glob.glob(documents_directory)\n",
    "    for file in files:\n",
    "        with open(file, \"rb\") as data:\n",
    "            name = os.path.basename(file)\n",
    "            if not container_client.get_blob_client(name).exists():\n",
    "                container_client.upload_blob(name=name, data=data)\n",
    "                print(f\"Uploaded {name} to Blob Storage\")\n",
    "\n",
    "upload_sample_documents(\n",
    "    blob_connection_string=blob_connection_string,\n",
    "    blob_container_name=blob_container_name,\n",
    "    documents_directory= \"Documents/*.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998ab45",
   "metadata": {},
   "source": [
    "## Create a blob data source connector on Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f4f6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Source int-vec-blob created or updated!!!!\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SoftDeleteColumnDeletionDetectionPolicy\n",
    ")\n",
    "\n",
    "indexer_client = SearchIndexerClient(endpoint=endpoint, credential=credential)\n",
    "\n",
    "container = SearchIndexerDataContainer(name=blob_container_name)\n",
    "\n",
    "delete_policy = SoftDeleteColumnDeletionDetectionPolicy(\n",
    "    soft_delete_column_name=\"isDeleted\",\n",
    "    soft_delete_marker_value=\"true\"\n",
    ")\n",
    "\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name = f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=blob_connection_string,\n",
    "    container=container,\n",
    "    data_deletion_detection_policy=delete_policy\n",
    ")\n",
    "\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data Source {data_source.name} created or updated!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced830c",
   "metadata": {},
   "source": [
    "**This code does the following:**\n",
    "\n",
    "`- Connects to your Azure Cognitive Search service.`\n",
    "\n",
    "`- Tells Search which Blob Storage container to read files from.`\n",
    "\n",
    "`- Configures the data source and deletion policy.`\n",
    "\n",
    "`- Creates or updates the data source in Azure Search.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b50531",
   "metadata": {},
   "source": [
    "## Create a search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int-vec created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField, \n",
    "    SearchFieldDataType, \n",
    "    VectorSearch, \n",
    "    HnswAlgorithmConfiguration, \n",
    "    VectorSearchProfile, \n",
    "    AzureOpenAIVectorizer, \n",
    "    AzureOpenAIVectorizerParameters, \n",
    "    SemanticConfiguration, \n",
    "    SemanticSearch, \n",
    "    SemanticPrioritizedFields, \n",
    "    SemanticField, \n",
    "    SearchIndex,\n",
    ")\n",
    "## These are all the building blocks to define an index, vector search, semantic search and fields. \n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "\n",
    "fields = [  \n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  \n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=azure_openai_model_dimensions, vector_search_profile_name=\"myHnswProfile\"),  \n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            parameters=AzureOpenAIVectorizerParameters(  \n",
    "                resource_url=azure_openai_endpoint,  \n",
    "                deployment_name=azure_openai_embedding_deployment,\n",
    "                model_name=azure_openai_model_name,\n",
    "                api_key=azure_openai_key,\n",
    "            ),\n",
    "        ),  \n",
    "    ],  \n",
    ") \n",
    "\n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        content_fields=[SemanticField(field_name=\"chunk\")],\n",
    "        title_field=SemanticField(field_name=\"title\")\n",
    "    ),  \n",
    ")\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name, \n",
    "    fields=fields, \n",
    "    vector_search=vector_search, \n",
    "    semantic_search=semantic_search\n",
    ")\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f\"{result.name} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18246d",
   "metadata": {},
   "source": [
    "**This code is setting up the blueprint (schema) for your search system in Azure.**\n",
    "\n",
    "`- Defines what data to store (fields).`\n",
    "\n",
    "`- Configures embeddings (vector_search).`\n",
    "\n",
    "`- Configures smart ranking (semantic_search).`\n",
    "\n",
    "`- Creates the index in Azure AI Search.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f00233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int-vec-skillset created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset\n",
    ")\n",
    "\n",
    "skillset_name = f\"{index_name}-skillset\"\n",
    "\n",
    "def create_skillset():\n",
    "    split_skill = SplitSkill(  \n",
    "        description=\"Split skill to chunk documents\",  \n",
    "        text_split_mode=\"pages\",  \n",
    "        context=\"/document\",  \n",
    "        maximum_page_length=2000,  \n",
    "        page_overlap_length=500,  \n",
    "        inputs=[  \n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "        ],  \n",
    "        outputs=[  \n",
    "            OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "        description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "        context=\"/document/pages/*\",  \n",
    "        resource_url=azure_openai_endpoint,  \n",
    "        deployment_name=azure_openai_embedding_deployment,  \n",
    "        model_name=azure_openai_model_name,\n",
    "        dimensions=azure_openai_model_dimensions,\n",
    "        api_key=azure_openai_key,  \n",
    "        inputs=[  \n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "        ],  \n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    index_projections = SearchIndexerIndexProjection(  \n",
    "        selectors=[  \n",
    "            SearchIndexerIndexProjectionSelector(  \n",
    "                target_index_name=index_name,  \n",
    "                parent_key_field_name=\"parent_id\",  \n",
    "                source_context=\"/document/pages/*\",  \n",
    "                mappings=[\n",
    "                    InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
    "                    InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),\n",
    "                    InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\")\n",
    "                ]\n",
    "            )\n",
    "        ],  \n",
    "        parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "            projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "        )  \n",
    "    )\n",
    "\n",
    "    skills = [split_skill, embedding_skill]\n",
    "\n",
    "    return SearchIndexerSkillset(  \n",
    "        name=skillset_name,  \n",
    "        description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "        skills=skills,  \n",
    "        index_projection=index_projections\n",
    "    )\n",
    "\n",
    "skillset = create_skillset()\n",
    "client = SearchIndexerClient(endpoint, credential)  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "434bfe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " int-vec-indexer is created and running. If queries return no results, please wait a bit and try again.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer\n",
    ")\n",
    "\n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "\n",
    "indexer_parameters = None\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,\n",
    "    parameters=indexer_parameters\n",
    ")  \n",
    "\n",
    "indexer_client = SearchIndexerClient(endpoint, credential)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} is created and running. If queries return no results, please wait a bit and try again.')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9058697",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c80a6946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: aHR0cHM6Ly9ocnBvbGljeWRvY3VtZW50cy5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50LXZlYy9TYWJiYXRpY2FsX0xvbmclMjBMZWF2ZSUyMFBvbGljeS1PZmZzaG9yZS5wZGY1\n",
      "chunk_id: dd87115b449e_aHR0cHM6Ly9ocnBvbGljeWRvY3VtZW50cy5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50LXZlYy9TYWJiYXRpY2FsX0xvbmclMjBMZWF2ZSUyMFBvbGljeS1PZmZzaG9yZS5wZGY1_pages_1\n",
      "Score: 0.8023779\n",
      "Content: • Full-Time employees may undertake a maximum of 2 sabbaticals during their tenure at Affine \n",
      "\n",
      "• An employee will not be eligible to take sabbatical twice in a year \n",
      "\n",
      "• Each sabbatical will be for a period of up to 3 months only. In case of longer duration, the same  \n",
      "\n",
      "needs to be approved by VP/CEO \n",
      "\n",
      "• There should be a gap of at least one year between two subsequent sabbatical leaves \n",
      "\n",
      "• Sabbatical leave will be an unpaid leave with no entitlements like health insurance, PF, Gratuityetc.  \n",
      "\n",
      "Eligible leave will not be adjusted against Sabbatical leave \n",
      "\n",
      "• Employee will not be eligible for any allowance/ reimbursements / Earned Leave will be paid \n",
      "\n",
      "/credited during the sabbatical leave \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Affine Analytics Private Limited \n",
      " \n",
      "453, BBMP No. 351/453, 4th sector, HSR Layout, Bangalore, KA, IN – 560102.                                                                                       Affine Confidential \n",
      "Tel: +91-80-6569-0996 | Web: affine.ai | Mail: info@affine.ai                                                                                               CIN No: U74999KA2011PTC057118  \n",
      "\n",
      "Terms and conditions \n",
      "\n",
      "• A sabbatical will not result in a break in employment. However, provisions dependent upon \n",
      "length of service i.e. annual leave, sick leave, and maternity leave will be deemed to be \n",
      "suspended during the period of the sabbatical \n",
      "\n",
      "• The employee availing sabbatical leave cannot work for another company, while in employment \n",
      "at Affine \n",
      "\n",
      "• The employee should be sent any information that the reporting manager considers relevant in \n",
      "relation to developments within their team in order to keep the employee up to date. This can be \n",
      "sent on personal email/mobile phone \n",
      "\n",
      "• The employee will remain on their current terms and conditions of assignment although not at \n",
      "Work. \n",
      "\n",
      "• If Performance appraisal is due during the sabbatical leave, the individual will have to complete \n",
      "the appraisals before commencement of sabbatical leave\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "query = \"What are the eligibility criteria defined in Affine’s Sabbatical Leave Policy?\"\n",
    "  \n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780476e",
   "metadata": {},
   "source": [
    "## Performa a Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91231f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: aHR0cHM6Ly9ocnBvbGljeWRvY3VtZW50cy5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50LXZlYy9TYWJiYXRpY2FsX0xvbmclMjBMZWF2ZSUyMFBvbGljeS1PZmZzaG9yZS5wZGY1\n",
      "chunk_id: dd87115b449e_aHR0cHM6Ly9ocnBvbGljeWRvY3VtZW50cy5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50LXZlYy9TYWJiYXRpY2FsX0xvbmclMjBMZWF2ZSUyMFBvbGljeS1PZmZzaG9yZS5wZGY1_pages_1\n",
      "Score: 0.030000001192092896\n",
      "Content: • Full-Time employees may undertake a maximum of 2 sabbaticals during their tenure at Affine \n",
      "\n",
      "• An employee will not be eligible to take sabbatical twice in a year \n",
      "\n",
      "• Each sabbatical will be for a period of up to 3 months only. In case of longer duration, the same  \n",
      "\n",
      "needs to be approved by VP/CEO \n",
      "\n",
      "• There should be a gap of at least one year between two subsequent sabbatical leaves \n",
      "\n",
      "• Sabbatical leave will be an unpaid leave with no entitlements like health insurance, PF, Gratuityetc.  \n",
      "\n",
      "Eligible leave will not be adjusted against Sabbatical leave \n",
      "\n",
      "• Employee will not be eligible for any allowance/ reimbursements / Earned Leave will be paid \n",
      "\n",
      "/credited during the sabbatical leave \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Affine Analytics Private Limited \n",
      " \n",
      "453, BBMP No. 351/453, 4th sector, HSR Layout, Bangalore, KA, IN – 560102.                                                                                       Affine Confidential \n",
      "Tel: +91-80-6569-0996 | Web: affine.ai | Mail: info@affine.ai                                                                                               CIN No: U74999KA2011PTC057118  \n",
      "\n",
      "Terms and conditions \n",
      "\n",
      "• A sabbatical will not result in a break in employment. However, provisions dependent upon \n",
      "length of service i.e. annual leave, sick leave, and maternity leave will be deemed to be \n",
      "suspended during the period of the sabbatical \n",
      "\n",
      "• The employee availing sabbatical leave cannot work for another company, while in employment \n",
      "at Affine \n",
      "\n",
      "• The employee should be sent any information that the reporting manager considers relevant in \n",
      "relation to developments within their team in order to keep the employee up to date. This can be \n",
      "sent on personal email/mobile phone \n",
      "\n",
      "• The employee will remain on their current terms and conditions of assignment although not at \n",
      "Work. \n",
      "\n",
      "• If Performance appraisal is due during the sabbatical leave, the individual will have to complete \n",
      "the appraisals before commencement of sabbatical leave\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the eligibility criteria defined in Affine’s Sabbatical Leave Policy?\"\n",
    "\n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec368de5",
   "metadata": {},
   "source": [
    "## Perform a Hybrid Search + Semantic Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ff995d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Answer: Eligibility   •<em> Full time employees with a minimum tenure of one year at Affine </em>  •<em> Should have a valid reason or need for the leave, for example: </em>  •<em> Pursue higher education or Medical emergency for self or family </em> •<em> Pursue their area of interest   Process </em>  • The employee should discuss and take a written approval from the Reporting Manager an...\n",
      "Semantic Answer Score: 0.9980000257492065\n",
      "\n",
      "parent_id: aHR0cHM6Ly9ocnBvbGljeWRvY3VtZW50cy5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50LXZlYy9TYWJiYXRpY2FsX0xvbmclMjBMZWF2ZSUyMFBvbGljeS1PZmZzaG9yZS5wZGY1\n",
      "chunk_id: dd87115b449e_aHR0cHM6Ly9ocnBvbGljeWRvY3VtZW50cy5ibG9iLmNvcmUud2luZG93cy5uZXQvaW50LXZlYy9TYWJiYXRpY2FsX0xvbmclMjBMZWF2ZSUyMFBvbGljeS1PZmZzaG9yZS5wZGY1_pages_0\n",
      "Reranker Score: 3.361161470413208\n",
      "Content: Affine Analytics Private Limited \n",
      " \n",
      "453, BBMP No. 351/453, 4th sector, HSR Layout, Bangalore, KA, IN – 560102.                                                                                       Affine Confidential \n",
      "Tel: +91-80-6569-0996 | Web: affine.ai | Mail: info@affine.ai                                                                                               CIN No: U74999KA2011PTC057118  \n",
      "\n",
      "Sabbatical Leave Policy \n",
      "\n",
      "Introduction \n",
      "\n",
      "At Affine, we understand that our employees manage competing priorities hence this policy is \n",
      "\n",
      "designed to give them the opportunity to take a career break for specific reasons for a pre[1]determined  \n",
      "\n",
      "time period. \n",
      "\n",
      "Eligibility \n",
      "\n",
      "• Full time employees with a minimum tenure of one year at Affine \n",
      "\n",
      "• Should have a valid reason or need for the leave, for example: \n",
      "\n",
      "• Pursue higher education or Medical emergency for self or family \n",
      "• Pursue their area of interest \n",
      "\n",
      "Process \n",
      "\n",
      "• The employee should discuss and take a written approval from the Reporting Manager and VP \n",
      "\n",
      "• The employee should apply for sabbatical leave at least 3 months in advance \n",
      "\n",
      "• The employee needs to undertake a commitment to remain engaged with Affine for at least 6  \n",
      "\n",
      "months following the return from sabbatical leave \n",
      "\n",
      "• The employee will be required to handover the laptop and his/ her email ID will be disabled \n",
      "\n",
      "• The employee should abide by the terms & condition of sabbatical leave \n",
      "\n",
      "Entitlement to sabbatical leave \n",
      "\n",
      "• Full-Time employees may undertake a maximum of 2 sabbaticals during their tenure at Affine \n",
      "\n",
      "• An employee will not be eligible to take sabbatical twice in a year \n",
      "\n",
      "• Each sabbatical will be for a period of up to 3 months only. In case of longer duration, the same  \n",
      "\n",
      "needs to be approved by VP/CEO \n",
      "\n",
      "• There should be a gap of at least one year between two subsequent sabbatical leaves \n",
      "\n",
      "• Sabbatical leave will be an unpaid leave with no entitlements like health insurance, PF, Gratuityetc.\n",
      "Caption: Eligibility   •<em> Full time employees with a minimum tenure of one year at Affine </em>  •<em> Should have a valid reason or need for the leave, for example: </em>  •<em> Pursue higher education or Medical emergency for self or family </em> •<em> Pursue their area of interest   Process </em>  • The employee should discuss and take a written approval from the Reporting Manager and.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")\n",
    "\n",
    "query = \"What are the eligibility criteria defined in Affine’s Sabbatical Leave Policy?\"\n",
    "\n",
    "search_client = SearchClient(endpoint, index_name, credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name='my-semantic-config',\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=1\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "if semantic_answers:\n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            print(f\"Semantic Answer: {answer.highlights}\")\n",
    "        else:\n",
    "            print(f\"Semantic Answer: {answer.text}\")\n",
    "        print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['chunk']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b22fad",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "`The Semantic Answer Score (0.998) is very high, meaning the first chunk you highlighted (with full eligibility + process details) is the most relevant and comprehensive match.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123089f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
